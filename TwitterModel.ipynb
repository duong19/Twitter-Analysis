{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "RANDOM_SEED = 2020\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./training.1600000.processed.noemoticon.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "         user_id                                               text  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4       joy_wolf                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'date', 'query', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = [\"NEGATIVE\", \"POSITIVE\"]\n",
    "def to_sentiment(sentiment):\n",
    "  sentiment = int(sentiment)\n",
    "  if sentiment == 4:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "df.sentiment = df.sentiment.apply(lambda x: to_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\astro\\miniconda3\\envs\\bigdata\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'NEGATIVE'), Text(1, 0, 'POSITIVE')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(df.sentiment)\n",
    "plt.xlabel('review sentiment')\n",
    "ax.set_xticklabels(decode_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy', lower=True, include_lengths= True)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "# Map data to fields\n",
    "fields = [('label', LABEL), ('id',None),('date',None),('query',None),\n",
    "      ('name',None), ('text', TEXT),('category',None)]\n",
    "\n",
    "# Apply field definition to create torch dataset\n",
    "dataset = data.TabularDataset(\n",
    "        path=\"training.csv\",\n",
    "        format=\"CSV\",\n",
    "        fields=fields,\n",
    "        skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 1280000\n",
      "Number of test data: 160000\n",
      "Number of validation data: 160000\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data, valid_data) = dataset.split(split_ratio=[0.8,0.1,0.1])\n",
    "\n",
    "print(\"Number of train data: {}\".format(len(train_data)))\n",
    "print(\"Number of test data: {}\".format(len(test_data)))\n",
    "print(\"Number of validation data: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [07:35, 1.89MB/s]                                                                                                                                                                             \n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 399999/400000 [00:22<00:00, 17736.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 798765),\n",
       " ('!', 722519),\n",
       " ('.', 647033),\n",
       " (' ', 469630),\n",
       " ('to', 452417),\n",
       " ('the', 417733),\n",
       " (',', 385991),\n",
       " ('a', 304663),\n",
       " ('my', 253099),\n",
       " ('it', 242828)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Most frequent tokens\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu())\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,210,257 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight\n",
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 8m 28s\n",
      "\tTrain Loss: 0.433 | Train Acc: 79.72%\n",
      "\t Val. Loss: 0.374 |  Val. Acc: 84.02%\n",
      "Epoch: 02 | Epoch Time: 7m 58s\n",
      "\tTrain Loss: 0.372 | Train Acc: 83.50%\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 84.78%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
