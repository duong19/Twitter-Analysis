{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "packages = \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1\"\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages {0} pyspark-shell\".format(packages)\n",
    ")\n",
    "from pyspark.sql.functions import *\n",
    "import json\n",
    "import sys\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "from model import RNN, preprocess_tweet\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df = spark.readStream.format(\"kafka\")\\\n",
    ".option(\"kafka.bootstrap.servers\", \"kafka:9092\")\\\n",
    ".option(\"subscribe\", \"Trump\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./model/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "\n",
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = 0\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n",
    "\n",
    "model.load_state_dict(torch.load('./model/tut2-model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    sentence = preprocess_tweet(sentence)\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    \n",
    "    if prediction.item() >= 0.5:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([                                                                                          \n",
    "        StructField(\"text\", StringType(), True),\n",
    "        StructField(\"retweet_count\", DoubleType(), True),\n",
    "        StructField(\"location\", StringType(), True),\n",
    "        StructField(\"favorite_count\", DoubleType(), True),\n",
    "        StructField(\"user_id\", StringType(), True),\n",
    "        StructField(\"place\", StringType(), True),\n",
    "        StructField(\"user_followers_count\", StringType(), True),\n",
    "    \n",
    "])\n",
    "\n",
    "kafka_df_string = kafka_df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "tweets_table = kafka_df_string.select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "one_row_udf = udf(predict_sentiment, StringType())\n",
    "\n",
    "tweets_table = tweets_table.withColumn('sentiment', one_row_udf(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tweets_table.writeStream.queryName(\"device_counts\").format(\"memory\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM device_counts').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_table.writeStream.trigger(processingTime='5 seconds')\\\n",
    ".format(\"csv\").outputMode(\"append\").option(\"checkpointLocation\", \"hdfs://namenode:9000/checkpoints\")\\\n",
    ".option('path', 'hdfs://namenode:9000/data/trump.csv').start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
