{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "packages = \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1\"\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages {0} pyspark-shell\".format(packages)\n",
    ")\n",
    "from pyspark.sql.functions import *\n",
    "import json\n",
    "import sys\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "from model import RNN, preprocess_tweet\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trumpDF = spark.readStream.format(\"kafka\")\\\n",
    ".option(\"kafka.bootstrap.servers\", \"kafka:9092\")\\\n",
    ".option(\"subscribe\", \"Trump\")\\\n",
    ".load()\n",
    "\n",
    "\n",
    "bidenDF = spark.readStream.format(\"kafka\")\\\n",
    ".option(\"kafka.bootstrap.servers\", \"kafka:9092\")\\\n",
    ".option(\"subscribe\", \"Biden\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./model/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "\n",
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = 0\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n",
    "\n",
    "model.load_state_dict(torch.load('./model/tut2-model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    sentence = preprocess_tweet(sentence)\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    if prediction.item() >= 0.5:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([   \n",
    "        StructField(\"time\", StringType(), True),\n",
    "        StructField(\"text\", StringType(), True),\n",
    "        StructField(\"retweet_count\", DoubleType(), True),\n",
    "        StructField(\"location\", StringType(), True),\n",
    "        StructField(\"favorite_count\", DoubleType(), True),\n",
    "        StructField(\"user_id\", StringType(), True),\n",
    "        StructField(\"place\", StringType(), True),\n",
    "        StructField(\"user_followers_count\", StringType(), True),\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "def castData(schema, df):\n",
    "    df = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    df = df.select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "    one_row_udf = udf(predict_sentiment, StringType())\n",
    "    df = df.withColumn('sentiment', one_row_udf(col('text')))\n",
    "    \n",
    "    return df\n",
    "    \n",
    "trumpDF = castData(schema, trumpDF)\n",
    "bidenDF = castData(schema, bidenDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = trumpDF.writeStream.queryName(\"device_counts\").format(\"memory\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+----------------+--------------+-------------------+-----+--------------------+---------+\n",
      "|                time|                text|retweet_count|        location|favorite_count|            user_id|place|user_followers_count|sentiment|\n",
      "+--------------------+--------------------+-------------+----------------+--------------+-------------------+-----+--------------------+---------+\n",
      "|Sun Dec 20 16:16:...|@TheRightMelissa ...|          0.0|        Virginia|           0.0|           43531918| null|                 319| Negative|\n",
      "|Sun Dec 20 16:16:...|High standing #Hi...|          0.0|            null|           0.0|1071784494326263800| null|                3732| Negative|\n",
      "|Sun Dec 20 16:16:...|@Mike_Pence @Perd...|          0.0|            null|           0.0|1040326859228102700| null|                   7| Negative|\n",
      "|Sun Dec 20 16:16:...|@chrissaccoccia1 ...|          0.0|            null|           0.0|1337382347260440600| null|                   9| Negative|\n",
      "|Sun Dec 20 16:16:...|REPORT: President...|          0.0|            null|           0.0|          623183897| null|                  43| Negative|\n",
      "|Sun Dec 20 16:16:...|How Donald Trump ...|          0.0|      Naples, FL|           0.0|           21599304| null|                 142| Negative|\n",
      "|Sun Dec 20 16:16:...|@GOPChairwoman @G...|          0.0|            null|           0.0| 717481779016241200| null|                 103| Negative|\n",
      "|Sun Dec 20 16:16:...|@mkraju @svdate @...|          0.0|    Evanston, IL|           0.0|           24400822| null|                 808| Negative|\n",
      "|Sun Dec 20 16:16:...|@CNNPolitics @cnn...|          0.0|      Dallas, TX|           0.0|          836854224| null|                  69| Positive|\n",
      "|Sun Dec 20 16:16:...|@SassBaller @GOP ...|          0.0|     Over The ðŸŒˆ|           0.0|1327021082986090500| null|                   3| Negative|\n",
      "|Sun Dec 20 16:16:...|This is bigger th...|          0.0|            null|           0.0| 992037864828555300| null|                 138| Negative|\n",
      "|Sun Dec 20 16:16:...|#MAGA2020 The tru...|          0.0|    Florida, USA|           0.0|          961540232| null|                  39| Negative|\n",
      "|Sun Dec 20 16:16:...|    Fight for Trump!|          0.0|      Dallas, TX|           0.0|         3220937827| null|                3152| Positive|\n",
      "|Sun Dec 20 16:16:...|WOAH: Trump Polit...|          0.0|Griffin, Georgia|           0.0| 986715151595458600| null|                 121| Negative|\n",
      "|Sun Dec 20 16:16:...|@CapehartJ @WhipC...|          0.0|            null|           0.0|1182247164149411800| null|                 172| Positive|\n",
      "|Sun Dec 20 16:16:...|Amen.\n",
      "\n",
      "Any public...|          0.0|            null|           0.0|           24789175| null|              183841| Positive|\n",
      "|Sun Dec 20 16:16:...|@calebbr39841173 ...|          0.0|        Anna, IL|           0.0|1262259146767978500| null|                   2| Negative|\n",
      "|Sun Dec 20 16:16:...|I hope he goes br...|          0.0|            null|           0.0|          290653867| null|                 202| Positive|\n",
      "|Sun Dec 20 16:16:...|@KevKuzo @Me_Spor...|          0.0|            null|           0.0|         3065921050| null|                   0| Negative|\n",
      "|Sun Dec 20 16:16:...|@MauriceHirsch4 @...|          0.0|          Israel|           0.0|         2799895176| null|                9937| Negative|\n",
      "+--------------------+--------------------+-------------+----------------+--------------+-------------------+-----+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM device_counts').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fe5483d18b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trumpDF.writeStream.trigger(processingTime='5 seconds')\\\n",
    ".format(\"csv\").outputMode(\"append\").option(\"checkpointLocation\", \"hdfs://namenode:9000/checkpoints\")\\\n",
    ".option('path', 'hdfs://namenode:9000/raw_data/trump.csv').start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fe51e8c7bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidenDF.writeStream.trigger(processingTime='5 seconds')\\\n",
    ".format(\"csv\").outputMode(\"append\").option(\"checkpointLocation\", \"hdfs://namenode:9000/checkpoints\")\\\n",
    ".option('path', 'hdfs://namenode:9000/raw_data/biden.csv').start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
